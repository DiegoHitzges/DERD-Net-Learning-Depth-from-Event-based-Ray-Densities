{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31dc98cc",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "\n",
    "This notebook shall be used for inference. For a given list of DSIs and possibly the according adaptive threshold filters, a trained model is loaded and then applied receive depthmap estimations.\n",
    "\n",
    "It relies on the classes and functions defined in *Classes_and_Functions.ipynb*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90dccc",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # OpenCV for adaptive filtering\n",
    "import psutil  # For system resource management\n",
    "from scipy.ndimage import convolve  # To convolve filtering masks\n",
    "\n",
    "# PyTorch specific imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset, Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e55f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebooks\n",
    "import import_ipynb\n",
    "from Classes_and_Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f0762d",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "\n",
    "First, we load our trained models. For a runtime analysis, only load a single model: set <b>num_models = 1</b>. To leverage ensemble learning, set <b>num_models > 1</b> and load the parameters for each individual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 1 #  How many models. Set to 1 for runtime analysis.\n",
    "multi_pixel = False #  Single or multi-pixel version of the network\n",
    "sub_frame_radius_h = 3 #  Radius of the Sub-DSIs\n",
    "sub_frame_radius_w = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = [PixelwiseConvGRU(sub_frame_radius_h, sub_frame_radius_w, multi_pixel=multi_pixel) for _ in range(num_models)]\n",
    "# Send to cuda\n",
    "if torch.cuda.is_available():\n",
    "    for model in models:\n",
    "        model.cuda()\n",
    "# Print architecture\n",
    "print(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ec4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to load models from directory\n",
    "model_paths = [None] * num_models\n",
    "# Give names of model files\n",
    "model_files = [\"final/mvsec_stereo/flying1_stereo_model_even\", \"final/mvsec_stereo/flying1_stereo_model_odd\"] #  [\"test/example_model_epoch_1\"] * num_models\n",
    "# Do not forget \".pth\"\n",
    "for idx, model_file in enumerate(model_files):\n",
    "    if not model_file.endswith(\".pth\"):\n",
    "        model_files[idx] += \".pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bccb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models parameters\n",
    "for idx, model in enumerate(models):\n",
    "    model.load_parameters(model_files[idx], device=device, model_path=model_paths[idx], optimizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d12896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ensemble learning to create averaged model\n",
    "model = AveragedNetwork(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1e314",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We want to estimate depth for a given set of DSIs and adaptive gaussian threshold filters. If DSIs are not given yet, load them. If Threshold filters are not given yet, compute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642865fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi_list = None #  Give here\n",
    "threshold_mask_list = None #  Give here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DSIs from a directory\n",
    "dsi_directory = \"/home/diego/Stereo Depth Estimation/data/mvsec/indoor_flying1/dsi/\" #  \"example_dsi_directory\"\n",
    "start_idx, end_idx = 0, None\n",
    "if dsi_list is None or dsi_list == []:\n",
    "    dsi_list = load_dsi_list(dsi_directory, start_idx, end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original filter parameters for MVSEC indoor flying and DSEC zurich city 04a\n",
    "\"\"\"\n",
    "Mvsec indoor flying 1,2,3:\n",
    "    Original: filter_size = 5 | adaptive_threshold_c = -14\n",
    "    Denser: filter_size = 9 | adaptive_threshold_c = -10\n",
    "    max_confidence =  [57.7, 78, 78.8]\n",
    "DSEC zurich city 04a:\n",
    "    filter_size = 5 | adaptive_threshold_c = -4 | max_confidence = 468\n",
    "\"\"\"\n",
    "\n",
    "# Choose filter parameters\n",
    "filter_size = 9 #  (int): Determines the size of the neighbourhood area when applying the adaptive threshold filter\n",
    "adaptive_threshold_c = -14 #  (int): Constant that is subtracted from the mean of the neighbourhood pixels when apply the adaptive threshold filter.\n",
    "max_confidence = 57.7 #  (int): The maximum relevant ray count in the DSI sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eae6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create threshold masks\n",
    "if threshold_mask_list is None or threshold_mask_list == []:\n",
    "    threshold_mask_list = [get_threshold_mask(dsi, filter_size, adaptive_threshold_c, max_confidence) for dsi in dsi_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291dc8be",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "The estimated depthmaps are generated by creating an instance of the *Estimated_Depthmaps* class.\n",
    "\n",
    "They are stored under <b>self.estimated_depths</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf98aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "inference = Estimated_Depthmaps(model,\n",
    "                                dsi_list,\n",
    "                                threshold_mask_list,\n",
    "                                # Input creation (Sub-DSIs)\n",
    "                                sub_frame_radius_h=sub_frame_radius_h,\n",
    "                                sub_frame_radius_w=sub_frame_radius_w,\n",
    "                                batch_size=1024\n",
    "                               )\n",
    "ct = time.time()\n",
    "print(\"Inference Time [sec]:\", round(ct-st,2), \"\\n\")\n",
    "# print(inference.estimated_depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbbb875",
   "metadata": {},
   "source": [
    "# Visualize\n",
    "\n",
    "The method <b>self.create_colored_depth_estimations()</b> applies the 'jet' colormap to them.\n",
    "\n",
    "The colored depthmaps are then stored under <b>self.colored_depth_estimations</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color depthmaps\n",
    "inference.create_colored_depth_estimations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the following cell will plot the colored depthmap estimations\n",
    "figsize=(10,6)\n",
    "for depthmap in inference.colored_depth_estimations:\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(depthmap)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
