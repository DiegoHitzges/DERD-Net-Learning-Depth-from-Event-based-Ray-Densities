# Learning Depth from Event-based Ray Densities

This is the repository for the conference paper ...

The aim is to learn depth from event-camera data. For this, we employ a mix of a geometric and a learning based approach. The events are processed into disparity space images, being a . This is based on the paper ... Then, pixels with su

A DSI represents the potential depth of each pixel across multiple disparity levels by counting the rays passing through each voxel, projected from the pixel where an event was triggered~\cite{Rebecq18ijcv}. In stereo event vision, DSIs from two or more cameras can be fused, eliminating the need for event synchronization between cameras. This reduces complexity and allows for more robust depth estimation.
